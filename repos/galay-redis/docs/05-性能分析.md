# 性能分析

## 基准测试数据

测试环境：本地 Redis `127.0.0.1:6379`，macOS。

| 场景 | 命令 | 耗时 | 成功数 | Ops/sec | 成功率 |
|------|------|------|--------|---------|--------|
| 普通模式（小规模） | `benchmark 10 100` | 75ms | 2,000 | 26,666 | 100% |
| 普通模式（压测） | `benchmark 50 500` | 445ms | 50,000 | 112,359 | 100% |
| Pipeline 压测 | `benchmark 20 5000 pipeline 100` | 91ms | 100,000 | 1,098,901 | 100% |

### 运行基准测试

```bash
# 普通模式：客户端数 操作次数
./build/test/test_redis_client_benchmark 10 100

# Pipeline 模式：客户端数 操作次数 pipeline 批大小
./build/test/test_redis_client_benchmark 20 5000 pipeline 100
```

## 不同场景的预期性能

### 按网络环境

| 场景 | 单命令 QPS | Pipeline(100) QPS |
|------|-----------|-------------------|
| 本地回环 | ~14,000 | ~1,400,000 |
| 局域网 (0.5ms) | ~1,900 | ~190,000 |
| 跨机房 (5ms) | ~200 | ~20,000 |

### 按并发数（本地回环）

| 客户端数 | 单命令 QPS | Pipeline(100) QPS |
|---------|-----------|-------------------|
| 1 | 14,000 | 1,400,000 |
| 10 | 130,000 | — |
| 50 | 600,000 | — |

## 性能瓶颈分析

```text
网络延迟      > 95%    ← 主要瓶颈
Redis 服务器    2-3%
客户端开销      < 2%    （协议编解码、状态机、内存分配）
超时检查        < 0.1%  （1 次条件判断）
```

网络延迟是绝对主导因素。客户端侧的优化空间有限，Pipeline 是最有效的优化手段。

## 内存开销

RedisClientAwaitable 实例大小约 228 字节，主要组成：

| 成员 | 大小 |
|------|------|
| `m_client` (引用) | 8B |
| `m_cmd` (string) | 32B |
| `m_args` (vector) | 24B |
| `m_encoded_cmd` (string) | 32B |
| `m_values` (vector) | 24B |
| `m_send_awaitable` (optional) | ~40B |
| `m_recv_awaitable` (optional) | ~40B |
| `m_result` (expected) | 8B |
| 其他 | ~20B |

## 优化建议

### 1. 使用 Pipeline

最直接有效的优化。将多个命令打包发送，减少网络往返次数。

```cpp
// 逐个执行：~14,000 ops/sec
for (int i = 0; i < 1000; ++i) {
    co_await client.set("key" + std::to_string(i), "value");
}

// Pipeline：~1,400,000 ops/sec（100x 提升）
std::vector<std::vector<std::string>> commands;
for (int i = 0; i < 1000; ++i) {
    commands.push_back({"SET", "key" + std::to_string(i), "value"});
}
co_await client.pipeline(commands);
```

### 2. 合理的批大小

| 批大小 | 特点 |
|--------|------|
| < 10 | 网络往返次数多，Pipeline 优势不明显 |
| 100-500 | 推荐范围，平衡性能和内存 |
| > 1000 | 内存占用高，单次延迟大 |

### 3. 多客户端并发

```cpp
// 单客户端：~14,000 ops/sec
// 10 个并发客户端：~130,000 ops/sec
for (int i = 0; i < 10; ++i) {
    scheduler->spawn(worker(scheduler, i));
}
```

### 4. 连接池

高并发场景使用连接池避免频繁创建/销毁连接：

```cpp
auto config = ConnectionPoolConfig::create("127.0.0.1", 6379, 4, 20);
// min_connections: CPU 核心数
// max_connections: 峰值并发数的 1.5-2 倍
```

### 5. 超时设置

根据操作类型设置合理的超时：

```cpp
// 快速操作
co_await client.get("key").timeout(std::chrono::seconds(1));

// 批量操作
co_await client.pipeline(batch).timeout(std::chrono::seconds(30));

// 非关键操作可以不设超时
co_await client.set("cache_key", "value");
```

### 6. 连接池调优

```cpp
// 如果 waiting_requests 经常 > 0 → 增加 max_connections
// 如果 peak_active_connections 远小于 max_connections → 减小 max_connections
// 如果 avg_acquire_time_ms 过高 → 增加连接数或优化 Redis 性能
auto stats = pool.getStats();
```

## 与其他客户端的理论对比

| 客户端 | 语言 | 模型 | 单线程 QPS (本地) |
|--------|------|------|------------------|
| hiredis | C | 同步 | ~20,000 |
| redis-plus-plus | C++ | 同步 | ~15,000 |
| galay-redis RedisClient | C++ | 协程 | ~14,000 |

协程模型的优势不在单线程性能，而在于并发能力——单线程内可以同时处理大量连接，无需线程切换开销。
