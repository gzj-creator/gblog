from typing import AsyncGenerator, List

from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

from src.config import settings
from src.core.vector_store import VectorStoreManager
from src.utils.logger import get_logger

logger = get_logger(__name__)

SYSTEM_PROMPT = """ä½ æ˜¯ Galay æ¡†æ¶çš„ AI åŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”å…³äº Galay é«˜æ€§èƒ½ C++ ç½‘ç»œæ¡†æ¶çš„é—®é¢˜ã€‚

Galay æ˜¯ä¸€ä¸ªåŸºäº C++20/23 åç¨‹çš„é«˜æ€§èƒ½å¼‚æ­¥ç½‘ç»œæ¡†æ¶ï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š
- galay-kernel: æ ¸å¿ƒåç¨‹è¿è¡Œæ—¶ï¼Œæ”¯æŒ kqueue/epoll/io_uring å¤šåç«¯
- galay-ssl: TLS/SSL ä¼ è¾“å±‚ï¼ŒåŸºäº OpenSSL çš„å¼‚æ­¥åŠ å¯†é€šä¿¡ï¼Œæ”¯æŒ SNI/ALPN/Session å¤ç”¨
- galay-http: HTTP/1.1 + HTTP/2 + WebSocket åè®®å®ç°ï¼Œæ”¯æŒåŒæ­¥ä¸åç¨‹å¼‚æ­¥
- galay-rpc: RPC æ¡†æ¶ï¼Œæ”¯æŒ unary/åŒå‘æµ/æœåŠ¡å‘ç°
- galay-redis: åç¨‹ Redis å®¢æˆ·ç«¯ï¼Œæ”¯æŒ Pipeline æ‰¹å¤„ç†ä¸è¶…æ—¶æ§åˆ¶
- galay-mysql: åç¨‹ MySQL å®¢æˆ·ç«¯ï¼Œæ”¯æŒé¢„å¤„ç†è¯­å¥ä¸äº‹åŠ¡
- galay-mongo: MongoDB å®¢æˆ·ç«¯ï¼Œæ”¯æŒ OP_MSG åè®®ã€SCRAM-SHA-256 è®¤è¯ä¸å¼‚æ­¥ Pipeline
- galay-etcd: etcd v3 å®¢æˆ·ç«¯ï¼Œæ”¯æŒ KV/Lease/Pipeline æ“ä½œ
- galay-utils: å·¥å…·åº“ï¼ˆçº¿ç¨‹æ± ã€ä¸€è‡´æ€§å“ˆå¸Œã€ç†”æ–­å™¨ç­‰ï¼‰
- galay-mcp: MCP åè®®å®ç°ï¼Œæ”¯æŒ Stdio ä¸ HTTP ä¼ è¾“

å›ç­”è¦æ±‚ï¼š
1. å‡†ç¡®å¼•ç”¨æ–‡æ¡£å†…å®¹
2. æä¾›ä»£ç ç¤ºä¾‹ï¼ˆå¦‚æœç›¸å…³ï¼‰
3. è¯´æ˜æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚æœç›¸å…³ï¼‰
4. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®å‘ŠçŸ¥
5. ä½¿ç”¨ä¸­æ–‡å›ç­”
6. ä¿æŒä¸“ä¸šå’Œå‹å¥½çš„è¯­æ°”
7. ä¸è¦ä½¿ç”¨ emoji æˆ–èŠ±å“¨ç¬¦å·ï¼ˆå¦‚ âœ…ğŸŒŸğŸ”¥ğŸ“Œï¼‰
8. è¾“å‡ºè¦ç»“æ„åŒ–åˆ†å—ï¼šå…ˆç®€è¦ç»“è®ºï¼Œå†ç”¨ 1. 2. 3. åˆ—ç‚¹è¯´æ˜"""


class RAGService:
    """RAG æ£€ç´¢å¢å¼ºç”ŸæˆæœåŠ¡"""

    def __init__(self, vector_store: VectorStoreManager):
        self._vector_store = vector_store
        self._llm = ChatOpenAI(
            model=settings.MODEL_NAME,
            temperature=settings.TEMPERATURE,
            openai_api_key=settings.OPENAI_API_KEY,
            openai_api_base=settings.OPENAI_API_BASE,
        )

    def retrieve(self, query: str, k: int = 4) -> List[Document]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"""
        return self._vector_store.search(query, k=k)

    def generate(self, query: str, context_docs: List[Document]) -> str:
        """åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆå›ç­”"""
        messages = self._build_messages(query, context_docs)
        response = self._llm.invoke(messages)
        return response.content

    async def generate_stream(
        self, query: str, context_docs: List[Document]
    ) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆå›ç­”"""
        messages = self._build_messages(query, context_docs)
        async for chunk in self._llm.astream(messages):
            if chunk.content:
                yield chunk.content

    def _build_messages(self, query: str, context_docs: List[Document]) -> list:
        """æ„å»º LLM æ¶ˆæ¯åˆ—è¡¨"""
        context = "\n\n".join(doc.page_content for doc in context_docs)

        system_content = f"""{SYSTEM_PROMPT}

è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

{context}"""

        return [
            SystemMessage(content=system_content),
            HumanMessage(content=query),
        ]
